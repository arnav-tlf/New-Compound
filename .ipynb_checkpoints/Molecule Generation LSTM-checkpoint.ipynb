{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtuqfFZSGdev"
   },
   "source": [
    "# Machine Learning Project (Drug Design)\n",
    "#### Approach to the problem\n",
    "1- **Selection of the Network Architecture (VAE composed of LSTM Encoder & Decoder)**\n",
    "- Data collection in **SMILES** format.\n",
    "- SMILES represent the chemical compounds in string format.\n",
    "- Since this is a **sequence task, LSTM** is the preferred choice of the neural network architecture for generating new SMILES string.\n",
    "\n",
    "2- **Data Preprocessing Steps**\n",
    "- Collect all the **unique characters** from the dataset.\n",
    "- Create **two dictionaries**, one mapping all the unique characters to the index while the other mapping index back to character.\n",
    "- Encode all the SMILES string into **one hot vectors** (character based) to feed into the network.\n",
    "- Append **start token** at the beginning of each SMILE string and **end token** to mark the end of the string. \n",
    "- Make all the SMILES string of **same length** for training in batch by padding smaller SMILE strings with end token.\n",
    "- **Labels will be shifted** by one unit from the inputs for **teacher forcing method** to train the sequence model.\n",
    "- Build the lstm encoder and decoder network.\n",
    "- Train the network end to end using one hot encoded SMILES string.\n",
    "\n",
    "3- **Inference from the decoder**\n",
    "- After training the network, feed random samples to the decoder to generate new SMILES string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKa6ApJjTI9r"
   },
   "source": [
    "## Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOtXb5EhPTGg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dLiad-WTvG6"
   },
   "source": [
    "### Set up google drive and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dpHYljjnk-n",
    "outputId": "feb6e7ae-9c62-4e2d-8cf1-c64bc44e92c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QRzH1dHT3Ln"
   },
   "source": [
    "### Extract data from zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "arUzvnN2odtW"
   },
   "outputs": [],
   "source": [
    "zip_dir = '/content/drive/MyDrive/drug_dataset/gdb11.tgz'\n",
    "extract_dir = '/tmp/'\n",
    "\n",
    "tar = tarfile.open(zip_dir, 'r')\n",
    "tar.extractall(extract_dir)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6xLUObjpZAQ",
    "outputId": "c62710a8-c18a-46ba-d59e-75d5ae7fb0ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drivefs_ipc.0',\n",
       " 'gdb11_size07.smi',\n",
       " 'gdb11_size04.smi',\n",
       " 'gdb11_size01.smi',\n",
       " 'gdb11_size03.smi',\n",
       " 'gdb11_size08.smi',\n",
       " 'gdb11_size11.smi',\n",
       " 'drivefs_ipc.0_shell',\n",
       " 'gdb11_size06.smi',\n",
       " 'gdb11_size09.smi',\n",
       " 'gdb11_size05.smi',\n",
       " 'tmpzt0ny4ll',\n",
       " 'gdb11_size10.smi',\n",
       " 'gdb11_size02.smi']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the contents of extract_dir\n",
    "os.listdir(extract_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmAH5tBlT9jm"
   },
   "source": [
    "### Load smiles data into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "vFAnKfxMpKDZ",
    "outputId": "2eabdcc0-7827-4089-efd0-4b289c4b2a7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(C)(C)CC(C)(C)C</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)(C)CC(C)(C)N</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)(C)CC(C)(C)O</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)(C)CC(C)(C)F</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C)(C)CC(C)(F)F</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              smiles  col_2  col_3\n",
       "0  CC(C)(C)CC(C)(C)C      1      1\n",
       "1  CC(C)(C)CC(C)(C)N      2      1\n",
       "2  CC(C)(C)CC(C)(C)O      3      1\n",
       "3  CC(C)(C)CC(C)(C)F      4      1\n",
       "4  CC(C)(C)CC(C)(F)F      5      1"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smi_file = \"C:\\\\Users\\\\LENOVO LEGION\\\\Desktop\\\\Machine Learning\\\\New Compound\\\\fda.csv\"\n",
    "data_df = pd.read_csv(smi_file, delimiter = \"\\t\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eZ-WErkUIAT"
   },
   "source": [
    "### Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m161P7KkqW6b",
    "outputId": "31dcee6a-7980-4c1a-c8b5-d979933a9c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (399881,)\n",
      "Shape of x_val: (44432,)\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and validation set\n",
    "x_train, x_val = train_test_split(data_df['smiles'], test_size = 0.1, random_state = 42)\n",
    "\n",
    "print(f'Shape of x_train: {x_train.shape}')\n",
    "print(f'Shape of x_val: {x_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD3oaUFjdRrH"
   },
   "source": [
    "### Dictionary of unique characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rZ1tQFJGQJ-6",
    "outputId": "3ec5a049-b0cb-460e-cd2f-64fd2b52de4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character to integer dictionary: \n",
      " {'5': 0, '(': 1, '-': 2, '3': 3, 'c': 4, '!': 5, '4': 6, '=': 7, ']': 8, 'o': 9, 'F': 10, '2': 11, '#': 12, 'n': 13, '+': 14, 'O': 15, '1': 16, '[': 17, 'H': 18, 'E': 19, 'C': 20, ')': 21, 'N': 22}\n",
      "\n",
      "\n",
      "Integer to character dictionary: \n",
      " {0: '5', 1: '(', 2: '-', 3: '3', 4: 'c', 5: '!', 6: '4', 7: '=', 8: ']', 9: 'o', 10: 'F', 11: '2', 12: '#', 13: 'n', 14: '+', 15: 'O', 16: '1', 17: '[', 18: 'H', 19: 'E', 20: 'C', 21: ')', 22: 'N'}\n"
     ]
    }
   ],
   "source": [
    "# Unique character set with start and end tokens\n",
    "char_set = set(''.join(list(data_df.smiles)) + '!E')\n",
    "\n",
    "# character to int mapping\n",
    "char_to_int = dict((c, i) for i, c in enumerate(char_set))\n",
    "\n",
    "# int to character mapping\n",
    "int_to_char = dict((i, c) for i, c in enumerate(char_set))\n",
    "\n",
    "# maximum length of sequence\n",
    "seq_len = max([len(smile) for smile in data_df.smiles]) + 2  \n",
    "\n",
    "print(f'Character to integer dictionary: \\n {char_to_int}')\n",
    "print('\\n')\n",
    "print(f'Integer to character dictionary: \\n {int_to_char}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-81-2nJ7umzF",
    "outputId": "e32881f0-6a57-4045-f018-0c7954ede4ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character set: {'5', '(', '-', '3', 'c', '!', '4', '=', ']', 'o', 'F', '2', '#', 'n', '+', 'O', '1', '[', 'H', 'E', 'C', ')', 'N'}\n",
      "Number of characters: 23\t Length of sequence: 31\n"
     ]
    }
   ],
   "source": [
    "print(f'Character set: {str(char_set)}')\n",
    "print(f'Number of characters: {len(char_set)}\\t Length of sequence: {seq_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ug-MLP-1ejMS"
   },
   "source": [
    "### One hot encoding of sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "sNNODypHRfBp"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(smiles_col):\n",
    "  # array of shape (num_examples, time_stamp, input_dim) initialized with zeros \n",
    "  one_hot =  np.zeros((smiles_col.shape[0], seq_len, len(char_set)), dtype = np.int8)\n",
    "  # iterate over each smile string\n",
    "  for index, smile in enumerate(smiles_col):\n",
    "    # encode the start token\n",
    "    one_hot[index, 0, char_to_int[\"!\"]] = 1\n",
    "    # encode the characters of smile string\n",
    "    for row, char in enumerate(smile):\n",
    "        one_hot[index, row + 1, char_to_int[char]] = 1\n",
    "    # encode the end token\n",
    "    one_hot[index, len(smile) + 1:, char_to_int['E']] = 1\n",
    "  # return input and the output\n",
    "  return one_hot[:, 0:-1, :], one_hot[:, 1:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Fz4ZwxJpbFw"
   },
   "source": [
    "### Visualize the one hot encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "-Ks-Q1qBTPiN",
    "outputId": "95dc0849-c58d-4728-af85-26f3a5c45c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC(=O)OC1(C)CC1O\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7877fa20b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 375.652x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One hot encoded train and validation data\n",
    "X_train, Y_train = one_hot_encoding(x_train.values)\n",
    "X_val, Y_val = one_hot_encoding(x_val.values)\n",
    "\n",
    "# Print the first smile string\n",
    "print(x_train.iloc[0])\n",
    "\n",
    "# show the one hot encoded version of the string\n",
    "plt.matshow(X_train[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "F-lv4e_WT_rB",
    "outputId": "89fba388-1f42-45b9-945b-51927ba2aaa4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'!CC(=O)OC1(C)CC1OEEEEEEEEEEEEE'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first smile string sequence with start and end tokens\n",
    "\"\".join([int_to_char[idx] for idx in np.argmax(X_train[0, :, :], axis = 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "hJuDhrG-UXUK"
   },
   "outputs": [],
   "source": [
    "# input shape of the model\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# output shape of the model\n",
    "output_dim = Y_train.shape[-1]\n",
    "\n",
    "# latent dimension \n",
    "latent_dim = 64\n",
    "\n",
    "# lstm units\n",
    "lstm_dim = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_UKjE32gvxb"
   },
   "source": [
    "### Build Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DHKdMp5myf_q"
   },
   "outputs": [],
   "source": [
    "# input layer of the encoder\n",
    "encoder_inputs = layers.Input(shape = input_shape)\n",
    "\n",
    "# internal states of the encoder (default activation is tanh)\n",
    "outputs, state_h, state_c = layers.LSTM(lstm_dim, return_state = True, unroll = False)(encoder_inputs)\n",
    "\n",
    "# concatenation of cell state and hidden state \n",
    "concat_states = layers.Concatenate(axis = -1)([state_h, state_c])\n",
    "\n",
    "latent_outputs = layers.Dense(latent_dim, activation = \"relu\")(concat_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YC80MShbhWFL"
   },
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySzfGD9TzaGO",
    "outputId": "a9f13b32-923a-4919-d844-6c3706be8aa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 23)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 64), (None,  22528       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           8256        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 30, 23)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 30, 64)       22528       input_2[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30, 23)       1495        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 63,127\n",
      "Trainable params: 63,127\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# decode the cell and hidden states of the encoder\n",
    "h_decoded =  layers.Dense(lstm_dim, activation = \"relu\")(latent_outputs)\n",
    "c_decoded =  layers.Dense(lstm_dim, activation = \"relu\")(latent_outputs)\n",
    "\n",
    "# decoded states\n",
    "decoded_states = [h_decoded, c_decoded]\n",
    "\n",
    "# input layer for decoder\n",
    "decoder_inputs = layers.Input(shape = input_shape)\n",
    "\n",
    "# hidden layers\n",
    "decoder_lstm = layers.LSTM(lstm_dim, return_sequences = True, unroll = False)\n",
    "decoder_outputs = decoder_lstm(decoder_inputs, initial_state = decoded_states)\n",
    "decoder_outputs = layers.Dense(output_dim, activation = 'softmax')(decoder_outputs)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFvtIunfiaFg"
   },
   "source": [
    "### Compile and fit the model\n",
    "- I stopped training after 65 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jZB53xkC4VvJ",
    "outputId": "fc8cc491-956d-4924-a56e-ca17cc523078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 240s 151ms/step - loss: 0.7433 - val_loss: 0.4505\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 0.3298 - val_loss: 0.2233\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 233s 149ms/step - loss: 0.1757 - val_loss: 0.1008\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 230s 147ms/step - loss: 0.0813 - val_loss: 0.0829\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 230s 147ms/step - loss: 0.0868 - val_loss: 0.0678\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 0.0607 - val_loss: 0.0700\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0485 - val_loss: 0.0235\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 227s 145ms/step - loss: 0.0284 - val_loss: 0.0313\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 0.0324 - val_loss: 0.0503\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 226s 144ms/step - loss: 0.0172 - val_loss: 0.0411\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 0.0150 - val_loss: 0.0053\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 226s 145ms/step - loss: 0.0187 - val_loss: 0.0063\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0102 - val_loss: 0.0063\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 226s 145ms/step - loss: 0.0078 - val_loss: 0.0210\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 227s 145ms/step - loss: 0.0174 - val_loss: 0.0051\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 229s 147ms/step - loss: 0.0095 - val_loss: 0.0023\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 226s 145ms/step - loss: 0.0073 - val_loss: 0.0019\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 226s 145ms/step - loss: 0.0206 - val_loss: 0.0021\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0195 - val_loss: 0.0031\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 224s 143ms/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 226s 145ms/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 227s 145ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 226s 145ms/step - loss: 0.0014 - val_loss: 0.0055\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 226s 144ms/step - loss: 0.0111 - val_loss: 0.0035\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 227s 145ms/step - loss: 0.0072 - val_loss: 0.0014\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 221s 141ms/step - loss: 0.0023 - val_loss: 7.9664e-04\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 226s 144ms/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 226s 144ms/step - loss: 0.0106 - val_loss: 7.0372e-04\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 8.4119e-04 - val_loss: 0.0031\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 221s 142ms/step - loss: 0.0073 - val_loss: 6.1456e-04\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 7.9866e-04 - val_loss: 0.0147\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0136 - val_loss: 9.3503e-04\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 226s 144ms/step - loss: 0.0023 - val_loss: 7.5584e-04\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 5.0965e-04 - val_loss: 0.0031\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 0.0040 - val_loss: 6.1628e-04\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0020 - val_loss: 5.8884e-04\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 224s 143ms/step - loss: 4.1418e-04 - val_loss: 8.7973e-04\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 0.0057 - val_loss: 4.0941e-04\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0019 - val_loss: 8.2496e-04\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0025 - val_loss: 3.6527e-04\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 224s 143ms/step - loss: 0.0019 - val_loss: 5.1204e-04\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 0.0012 - val_loss: 3.3908e-04\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0015 - val_loss: 5.6829e-04\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 3.0723e-04 - val_loss: 9.8649e-04\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 221s 142ms/step - loss: 6.6253e-04 - val_loss: 0.0029\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0093 - val_loss: 3.5841e-04\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 221s 142ms/step - loss: 5.4838e-04 - val_loss: 8.2228e-04\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0020 - val_loss: 3.1878e-04\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 4.2435e-04 - val_loss: 0.0026\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 225s 144ms/step - loss: 0.0024 - val_loss: 3.6896e-04\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 221s 141ms/step - loss: 2.8118e-04 - val_loss: 4.5647e-04\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 224s 143ms/step - loss: 0.0014 - val_loss: 5.6107e-04\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 2.4424e-04 - val_loss: 4.2483e-04\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0021 - val_loss: 2.6298e-04\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 9.4885e-04 - val_loss: 0.0018\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 224s 143ms/step - loss: 6.3832e-04 - val_loss: 6.6834e-04\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 2.9622e-04 - val_loss: 5.2756e-04\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 222s 142ms/step - loss: 0.0051 - val_loss: 3.5039e-04\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 223s 143ms/step - loss: 0.0010 - val_loss: 2.3008e-04\n",
      "Epoch 65/100\n",
      " 855/1563 [===============>..............] - ETA: 1:38 - loss: 2.3261e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-544540e9d1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set learning rate for the model\n",
    "learning_rate = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 10, min_lr = 0.000001, verbose = 1, min_delta = 1e-5)\n",
    "\n",
    "# set the optimizer for the model\n",
    "opt = tf.keras.optimizers.Adam(lr = 0.005) \n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = opt, loss = 'categorical_crossentropy')\n",
    "\n",
    "# fit the model\n",
    "model.fit([X_train, X_train], Y_train, epochs = 100, batch_size = 256, shuffle = True, callbacks = [learning_rate], validation_data = ([X_val, X_val], Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi27QR90izKy"
   },
   "source": [
    "### Model predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "eSvK6Dm45FPu"
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "  # extract index of maximum probability\n",
    "  idxs_pred = np.argmax(model.predict([X_val[i:i + 1], X_val[i:i + 1]]), axis = 2)\n",
    "\n",
    "  # join the predicted smile string\n",
    "  pred_smile = \"\".join([int_to_char[m] for m in idxs_pred[0]])[:-1]\n",
    "\n",
    "  # original smile string\n",
    "  idxs_original = np.argmax(X_val[i:i + 1], axis = 2)\n",
    "  true_smile =  \"\".join([int_to_char[n] for n in idxs_original[0]])[1:]\n",
    "  if true_smile != pred_smile:\n",
    "    print(f'True smile representation: {true_smile}\\n Predicted smile representation: {pred_smile}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl9qMfhlAr1z"
   },
   "source": [
    "### Smiles to latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "d0K-cGlX-c0X"
   },
   "outputs": [],
   "source": [
    "# construct the smiles to latent space model \n",
    "smiles_to_latent_space = tf.keras.Model(encoder_inputs, neck_outputs)\n",
    "\n",
    "# save the model\n",
    "smiles_to_latent_space.save(\"smile_latent.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OCqnXsECBkt9"
   },
   "outputs": [],
   "source": [
    "# convert validation data into latent space\n",
    "val_latent = smiles_to_latent_space.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIIp2SLlBAcp"
   },
   "source": [
    "### Latent space to lstm states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "oU-AV-0j-xGf"
   },
   "outputs": [],
   "source": [
    "# latent input layer for decoding smiles data\n",
    "latent_input = layers.Input(shape = (latent_dim,))\n",
    "\n",
    "# reuse earlier dense layers\n",
    "state_h_decoded =  model.get_layer('dense_1')(latent_input)\n",
    "state_c_decoded =  model.get_layer('dense_2')(latent_input)\n",
    "\n",
    "latent_to_states_model = tf.keras.Model(latent_input, [state_h_decoded, state_c_decoded])\n",
    "latent_to_states_model.save(\"latent_state.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FESNiztu6zMf"
   },
   "outputs": [],
   "source": [
    "# Model for random sampling\n",
    "sample_decoder_inputs = layers.Input(batch_shape = (1, 1, input_shape[1]))\n",
    "lstm_out = layers.LSTM(lstm_dim, return_sequences = True, unroll = False, stateful = True)(sample_decoder_inputs)\n",
    "dense_out = layers.Dense(output_dim, activation = 'softmax')(lstm_out)\n",
    "\n",
    "sample_model = tf.keras.Model(sample_decoder_inputs, dense_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TIRdrDc-_E2e"
   },
   "outputs": [],
   "source": [
    "# Model for random sampling\n",
    "inf_decoder_inputs = layers.Input(batch_shape = (1, 1, input_shape[1]))\n",
    "inf_decoder_lstm = layers.LSTM(lstm_dim, return_sequences = True, unroll = False, stateful = True)\n",
    "\n",
    "inf_decoder_outputs = inf_decoder_lstm(inf_decoder_inputs)\n",
    "inf_decoder_dense = layers.Dense(output_dim, activation = 'softmax')\n",
    "inf_decoder_outputs = inf_decoder_dense(inf_decoder_outputs)\n",
    "\n",
    "sample_model = tf.keras.Model(inf_decoder_inputs, inf_decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vSa0Edtd_ggG",
    "outputId": "b40bee55-803b-45d0-a479-9100e8c74b5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(1, 1, 23)]              0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (1, 1, 64)                22528     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (1, 1, 23)                1495      \n",
      "=================================================================\n",
      "Total params: 24,023\n",
      "Trainable params: 24,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Transfer learned weights\n",
    "for i in range(1, 3):\n",
    "  sample_model.layers[i].set_weights(model.layers[i + 6].get_weights())\n",
    "sample_model.save(\"sample_model.h5\")\n",
    "\n",
    "sample_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hR-SSw1XmIOQ"
   },
   "source": [
    "### This function will generate smiles from latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "HMH2pzNXAePn"
   },
   "outputs": [],
   "source": [
    "def latent_to_smiles(latent):\n",
    "  # decode states and Reset the LSTM cells\n",
    "  states = latent_to_states_model.predict(latent)\n",
    "  sample_model.layers[1].reset_states(states = [states[0], states[1]])\n",
    "  # Prepare the input char\n",
    "  start_idx = char_to_int[\"!\"]\n",
    "  sample_vec = np.zeros((1, 1, 23))\n",
    "  sample_vec[0, 0, start_idx] = 1\n",
    "  smiles = \"\"\n",
    "  # Loop and predict next char\n",
    "  for i in range(28):\n",
    "    out = sample_model.predict(sample_vec)\n",
    "    sample_idx = np.argmax(out)\n",
    "    sample_char = int_to_char[sample_idx]\n",
    "    if sample_char != \"E\":\n",
    "      smiles = smiles + int_to_char[sample_idx]\n",
    "      sample_vec = np.zeros((1, 1, 23))\n",
    "      sample_vec[0, 0, sample_idx] = 1\n",
    "    else:\n",
    "      break\n",
    "  return smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJiNUOmAoKyJ"
   },
   "source": [
    "### First generated SMILE string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TJfPi18BBsi-",
    "outputId": "02b78acf-d201-4638-b061-afcd4b799f4b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'CC1=C2OCC=C2C=C1'"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles = latent_to_smiles(val_latent[0:1])\n",
    "smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3DucSVfofn9"
   },
   "source": [
    "### Second generated SMILE string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WY3APeFkgjhX",
    "outputId": "754170d6-d64a-420c-8966-87aacf59b26e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'CC(O)C=C(F)C1CO1'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles = latent_to_smiles(val_latent[1:2])\n",
    "smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaHTQ6jfoiHv"
   },
   "source": [
    "### Third generated SMILE string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1Rlxzbo9gmau",
    "outputId": "a784ca35-7746-4ee9-df3d-0a671861502d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'ONC(=N)C1=CCC=C1'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles = latent_to_smiles(val_latent[2:3])\n",
    "smiles"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vae_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
